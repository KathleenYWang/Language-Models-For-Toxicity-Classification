{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxicity Baseline NB by Sub Categories Seperate vocab\n",
    "Competition location:  \n",
    "https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification  \n",
    "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vocab as vocabulary\n",
    "import collections\n",
    "import utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/ToxicityData/train.csv')\n",
    "test = pd.read_csv('/data/ToxicityData/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>Instead of wringing our hands and nibbling the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>how many of you commenters have garbage piled ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra...\n",
       "2  7000002  No it won't . That's just wishful thinking on ...\n",
       "3  7000003  Instead of wringing our hands and nibbling the...\n",
       "4  7000004  how many of you commenters have garbage piled ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "This can be as simple as calling string.split() - good enough for English and many European languages - but we could also do something more sophisticated here. There are various types of tokenizers:  \n",
    "  \n",
    "1. nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "2. nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "white_token = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "keras_token = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 30000\n",
    "SEED = 23\n",
    "VAL_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, tokenize everything to build vocab\n",
    "Only use vocabs from train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def check_frequency(data, n = 20):\n",
    "    stop = stopwords.words('english')\n",
    "    data  = data.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    data = data.str.replace('[^\\w\\s]','')\n",
    "    data = data.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    freq = pd.Series(' '.join(data).split()).value_counts()[:n]\n",
    "    return freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some of the common words for those with high targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "would     301263\n",
       "people    299566\n",
       "one       256929\n",
       "like      254760\n",
       "dont      218081\n",
       "trump     207496\n",
       "get       196602\n",
       "us        194333\n",
       "time      155511\n",
       "think     149475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump     21314\n",
       "people    19137\n",
       "like      17986\n",
       "stupid    13054\n",
       "would     12985\n",
       "dont      12800\n",
       "one       12589\n",
       "get       11991\n",
       "us         8988\n",
       "think      8155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['target'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shit      5\n",
       "kill      5\n",
       "hate      4\n",
       "burn      4\n",
       "time      3\n",
       "cut       3\n",
       "white     3\n",
       "lets      3\n",
       "like      3\n",
       "mother    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['severe_toxicity'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crap      1323\n",
       "damn      1319\n",
       "like      1263\n",
       "people    1236\n",
       "get       1138\n",
       "dont      1070\n",
       "would      902\n",
       "trump      897\n",
       "one        868\n",
       "ass        717\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['obscene'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white      3258\n",
       "black      2325\n",
       "people     2150\n",
       "muslims    1323\n",
       "muslim     1081\n",
       "like       1076\n",
       "gay        1014\n",
       "dont        961\n",
       "would       907\n",
       "one         800\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['identity_attack'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump     17863\n",
       "like      13927\n",
       "people    13730\n",
       "stupid    12464\n",
       "would      9538\n",
       "one        9412\n",
       "dont       9319\n",
       "get        8813\n",
       "us         6759\n",
       "think      6213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['insult'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kill      726\n",
       "shoot     351\n",
       "would     292\n",
       "people    277\n",
       "get       272\n",
       "death     229\n",
       "like      220\n",
       "dont      205\n",
       "one       198\n",
       "die       198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['threat'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex       853\n",
       "ass       568\n",
       "like      448\n",
       "get       413\n",
       "women     402\n",
       "sexual    382\n",
       "trump     367\n",
       "dont      354\n",
       "one       354\n",
       "would     345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_frequency(data = train[train['sexual_explicit'] > 0.5]['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389328"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a subdataset with most of the errors and build vocab based on that\n",
    "\n",
    "tokenize_all_one_list = white_token.tokenize(' '.join(train[train['target'] > 0.3]['comment_text'].tolist()))\n",
    "len(set(tokenize_all_one_list))\n",
    "\n",
    "# len of full set 1,670,966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 436152),\n",
       " ('to', 277566),\n",
       " ('and', 250531),\n",
       " ('a', 226490),\n",
       " ('of', 217753),\n",
       " ('is', 174734),\n",
       " ('in', 128942),\n",
       " ('that', 122927),\n",
       " ('you', 106297),\n",
       " ('for', 96415),\n",
       " ('are', 93919),\n",
       " ('I', 86955),\n",
       " ('be', 64616),\n",
       " ('with', 63462),\n",
       " ('have', 62827),\n",
       " ('not', 61590),\n",
       " ('on', 60931),\n",
       " ('it', 60722),\n",
       " ('they', 54347),\n",
       " ('as', 52734)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(tokenize_all_one_list).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('comfortable.', 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(tokenize_all_one_list).most_common(V)[-1]\n",
    "# compare to before this is a lot less frequent, but still seems reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 30kth token has 140 appearances, not too bad, we will use top 30k covab, and leave the rest as unknown\n",
    "This step takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocabulary.Vocabulary(tokenize_all_one_list, size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [vocab.words_to_ids(white_token.tokenize(train_row)) for train_row in train['comment_text'].tolist()]\n",
    "x_test = [vocab.words_to_ids(white_token.tokenize(test_row)) for test_row in test['comment_text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train['target'] > 0.5)\n",
    "y_sevtox_train = np.array(train['severe_toxicity'] > 0.5)\n",
    "y_obs_train = np.array(train['obscene'] > 0.5)\n",
    "y_idat_train = np.array(train['identity_attack'] > 0.5)\n",
    "y_ins_train = np.array(train['insult'] > 0.5)\n",
    "y_thr_train = np.array(train['threat'] > 0.5)\n",
    "y_expl_train = np.array(train['sexual_explicit'] > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([1 if i else 0 for i in y_train])\n",
    "y_sevtox_train = np.array([1 if i else 0 for i in y_sevtox_train])\n",
    "y_obs_train = np.array([1 if i else 0 for i in  y_obs_train])\n",
    "y_idat_train = np.array([1 if i else 0 for i in y_idat_train])\n",
    "y_ins_train = np.array([1 if i else 0 for i in  y_ins_train])\n",
    "y_thr_train = np.array([1 if i else 0 for i in y_thr_train])\n",
    "y_expl_train = np.array([1 if i else 0 for i in y_expl_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub class correlation\n",
    "### Make all the labels into one matrix\n",
    "And analyze the correlation between them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, target is highly correlated with 'insult'. This is probably because every time insult is high, target is high, meaning that all other categories can be viewed as insult. However, sexual explicit and threat could be different, i.e. for other types of negative comment, these two won't get flagged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict by sub categories\n",
    "Have to divide trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "indices = np.arange(len(x_train))\n",
    "\n",
    "rng.shuffle(indices)  # in-place\n",
    "\n",
    "x_train =  np.array(x_train)\n",
    "y_train =  np.array(y_train)\n",
    "\n",
    "\n",
    "# the indices slicing only works with np array\n",
    "\n",
    "x_train_s = x_train[indices]\n",
    "y_train_s = y_train[indices]\n",
    "\n",
    "y_sevtox_train_s = y_sevtox_train[indices]\n",
    "y_obs_train_s = y_obs_train[indices]\n",
    "y_idat_train_s = y_idat_train[indices]\n",
    "y_ins_train_s = y_ins_train[indices]\n",
    "y_thr_train_s = y_thr_train[indices]\n",
    "y_expl_train_s = y_expl_train[indices]\n",
    "\n",
    "split_idx = int(VAL_SPLIT * len(x_train))\n",
    "val_x = x_train_s[:split_idx]\n",
    "val_y = y_train_s[:split_idx]\n",
    "\n",
    "val_y_sevtox = y_sevtox_train[:split_idx]\n",
    "val_y_obs = y_obs_train[:split_idx]\n",
    "val_y_idat = y_idat_train[:split_idx]\n",
    "val_y_ins = y_ins_train[:split_idx]\n",
    "val_y_thr = y_thr_train[:split_idx]\n",
    "val_y_expl = y_expl_train[:split_idx]\n",
    "\n",
    "train_x = x_train_s[split_idx:]\n",
    "train_y  = y_train_s[split_idx:]\n",
    "\n",
    "train_y_sevtox = y_sevtox_train[split_idx:]\n",
    "train_y_obs = y_obs_train[split_idx:]\n",
    "train_y_idat = y_idat_train[split_idx:]\n",
    "train_y_ins = y_ins_train[split_idx:]\n",
    "train_y_thr = y_thr_train[split_idx:]\n",
    "train_y_expl = y_expl_train[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sb = utils.id_lists_to_sparse_bow(train_x, V)\n",
    "val_x_sb = utils.id_lists_to_sparse_bow(val_x, V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlike the previous case, we use 0.3 as the threshhold as determining if a label is toxic (down from 0.5)\n",
    "\n",
    "#### precision: how many predicted positive are actually positive\n",
    "#### recall: how much positive cases did you catch (doesn't work as well when large false positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n",
      "3\n",
      "1\n",
      "1263412\n",
      "Accuracy on test set: 91.20%\n",
      "precision: [0.97510879 0.35619541]\n",
      "recall: [0.93029443 0.61890369]\n",
      "fscore: [0.9521746  0.45216051]\n",
      "support: [509701  31761]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "print(train_x_sb[3][(0, 5)])\n",
    "print(train_y[3])\n",
    "print(val_x_sb[3][(0, 6)])\n",
    "print(val_y[3])\n",
    "print(train_x_sb.shape[0])\n",
    "nb.fit(train_x_sb, train_y)\n",
    "y_pred_val = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc = accuracy_score(val_y, y_pred_val)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y, y_pred_val)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set severe_toxicity: 89.81%\n",
      "precision: [1.00000000e+00 1.81205378e-05]\n",
      "recall: [0.8980813 1.       ]\n",
      "fscore: [9.46304356e-01 3.62404189e-05]\n",
      "support: [541461      1]\n"
     ]
    }
   ],
   "source": [
    "nb_sevtox = MultinomialNB()\n",
    "nb_sevtox.fit(train_x_sb, train_y_sevtox)\n",
    "y_pred_val_sevtox = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_sevtox = accuracy_score(val_y_sevtox, y_pred_val_sevtox)\n",
    "print(\"Accuracy on test set severe_toxicity: {:.02%}\".format(acc_sevtox))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_sevtox, y_pred_val_sevtox)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set obscene: 89.40%\n",
      "precision: [0.99491235 0.00505563]\n",
      "recall: [0.8980767  0.10134399]\n",
      "fscore: [0.94401772 0.00963082]\n",
      "support: [538709   2753]\n"
     ]
    }
   ],
   "source": [
    "nb_obs = MultinomialNB()\n",
    "nb_obs.fit(train_x_sb, train_y_obs)\n",
    "y_pred_val_obs = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_obs = accuracy_score(val_y_obs, y_pred_val_obs)\n",
    "print(\"Accuracy on test set obscene: {:.02%}\".format(acc_obs))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_obs, y_pred_val_obs)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set identity_attack: 89.52%\n",
      "precision: [0.99639505 0.00349726]\n",
      "recall: [0.89806975 0.0991778 ]\n",
      "fscore: [0.94468079 0.00675628]\n",
      "support: [539516   1946]\n"
     ]
    }
   ],
   "source": [
    "nb_idat = MultinomialNB()\n",
    "nb_idat.fit(train_x_sb, train_y_idat)\n",
    "y_pred_val_idat = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_idat = accuracy_score(val_y_idat, y_pred_val_idat)\n",
    "print(\"Accuracy on test set identity_attack: {:.02%}\".format(acc_idat))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_idat, y_pred_val_idat)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set insult: 86.29%\n",
      "precision: [0.95570006 0.04548255]\n",
      "recall: [0.89819292 0.10435723]\n",
      "fscore: [0.92605456 0.06335344]\n",
      "support: [517410  24052]\n"
     ]
    }
   ],
   "source": [
    "nb_ins = MultinomialNB()\n",
    "nb_ins.fit(train_x_sb, train_y_ins)\n",
    "y_pred_val_ins = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_ins = accuracy_score(val_y_ins, y_pred_val_ins)\n",
    "print(\"Accuracy on test set insult: {:.02%}\".format(acc_ins))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_ins, y_pred_val_ins)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set threat: 89.68%\n",
      "precision: [0.99836924 0.00173957]\n",
      "recall: [0.89808962 0.1079865 ]\n",
      "fscore: [0.94557817 0.00342399]\n",
      "support: [540573    889]\n"
     ]
    }
   ],
   "source": [
    "nb_thr = MultinomialNB()\n",
    "nb_thr.fit(train_x_sb, train_y_thr)\n",
    "y_pred_val_thr = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_thr = accuracy_score(val_y_thr, y_pred_val_thr)\n",
    "print(\"Accuracy on test set threat: {:.02%}\".format(acc_thr))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_thr, y_pred_val_thr)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set sexual_explicit: 89.65%\n",
      "precision: [0.99807722 0.00170333]\n",
      "recall: [0.89805952 0.09135083]\n",
      "fscore: [0.9454305 0.0033443]\n",
      "support: [540433   1029]\n"
     ]
    }
   ],
   "source": [
    "nb_expl = MultinomialNB()\n",
    "nb_expl.fit(train_x_sb, train_y_expl)\n",
    "y_pred_val_expl = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc_expl = accuracy_score(val_y_expl, y_pred_val_expl)\n",
    "print(\"Accuracy on test set sexual_explicit: {:.02%}\".format(acc_expl))\n",
    "\n",
    "precision, recall, fscore, support = score(val_y_expl, y_pred_val_expl)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the problems are insults. And that even though predicted accuracy is high, the precision is rather terrible, meaning that most of our predicted 'toxic comments' are not really toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hundredblocks/concrete_NLP_tutorial\n",
    "# modified to work with current set up\n",
    "\n",
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes ={}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance = get_most_important_features(count_vectorizer, clf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hundredblocks/concrete_NLP_tutorial\n",
    "def plot_important_words(top_scores, top_words, bottom_scores, bottom_words, name):\n",
    "    y_pos = np.arange(len(top_words))\n",
    "    top_pairs = [(a,b) for a,b in zip(top_words, top_scores)]\n",
    "    top_pairs = sorted(top_pairs, key=lambda x: x[1])\n",
    "    \n",
    "    bottom_pairs = [(a,b) for a,b in zip(bottom_words, bottom_scores)]\n",
    "    bottom_pairs = sorted(bottom_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words = [a[0] for a in top_pairs]\n",
    "    top_scores = [a[1] for a in top_pairs]\n",
    "    \n",
    "    bottom_words = [a[0] for a in bottom_pairs]\n",
    "    bottom_scores = [a[1] for a in bottom_pairs]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))  \n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.barh(y_pos,bottom_scores, align='center', alpha=0.5)\n",
    "    plt.title('Irrelevant', fontsize=20)\n",
    "    plt.yticks(y_pos, bottom_words, fontsize=14)\n",
    "    plt.suptitle('Key words', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.barh(y_pos,top_scores, align='center', alpha=0.5)\n",
    "    plt.title('Disaster', fontsize=20)\n",
    "    plt.yticks(y_pos, top_words, fontsize=14)\n",
    "    plt.suptitle(name, fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.show()\n",
    "\n",
    "top_scores = [a[0] for a in importance[1]['tops']]\n",
    "top_words = [a[1] for a in importance[1]['tops']]\n",
    "bottom_scores = [a[0] for a in importance[1]['bottom']]\n",
    "bottom_words = [a[1] for a in importance[1]['bottom']]\n",
    "\n",
    "plot_important_words(top_scores, top_words, bottom_scores, bottom_words, \"Most important words for relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
