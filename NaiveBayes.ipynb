{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxicity Baseline NB\n",
    "Competition location:  \n",
    "https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vocab as vocabulary\n",
    "import collections\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/ToxicityData/train.csv')\n",
    "test = pd.read_csv('/data/ToxicityData/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>Instead of wringing our hands and nibbling the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>how many of you commenters have garbage piled ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra...\n",
       "2  7000002  No it won't . That's just wishful thinking on ...\n",
       "3  7000003  Instead of wringing our hands and nibbling the...\n",
       "4  7000004  how many of you commenters have garbage piled ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                 59848\n",
       "target                                                                                 0\n",
       "comment_text                           This is so cool. It's like, 'would you want yo...\n",
       "severe_toxicity                                                                        0\n",
       "obscene                                                                                0\n",
       "identity_attack                                                                        0\n",
       "insult                                                                                 0\n",
       "threat                                                                                 0\n",
       "asian                                                                                NaN\n",
       "atheist                                                                              NaN\n",
       "bisexual                                                                             NaN\n",
       "black                                                                                NaN\n",
       "buddhist                                                                             NaN\n",
       "christian                                                                            NaN\n",
       "female                                                                               NaN\n",
       "heterosexual                                                                         NaN\n",
       "hindu                                                                                NaN\n",
       "homosexual_gay_or_lesbian                                                            NaN\n",
       "intellectual_or_learning_disability                                                  NaN\n",
       "jewish                                                                               NaN\n",
       "latino                                                                               NaN\n",
       "male                                                                                 NaN\n",
       "muslim                                                                               NaN\n",
       "other_disability                                                                     NaN\n",
       "other_gender                                                                         NaN\n",
       "other_race_or_ethnicity                                                              NaN\n",
       "other_religion                                                                       NaN\n",
       "other_sexual_orientation                                                             NaN\n",
       "physical_disability                                                                  NaN\n",
       "psychiatric_or_mental_illness                                                        NaN\n",
       "transgender                                                                          NaN\n",
       "white                                                                                NaN\n",
       "created_date                                               2015-09-29 10:50:41.987077+00\n",
       "publication_id                                                                         2\n",
       "parent_id                                                                            NaN\n",
       "article_id                                                                          2006\n",
       "rating                                                                          rejected\n",
       "funny                                                                                  0\n",
       "wow                                                                                    0\n",
       "sad                                                                                    0\n",
       "likes                                                                                  0\n",
       "disagree                                                                               0\n",
       "sexual_explicit                                                                        0\n",
       "identity_annotator_count                                                               0\n",
       "toxicity_annotator_count                                                               4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "This can be as simple as calling string.split() - good enough for English and many European languages - but we could also do something more sophisticated here. There are various types of tokenizers:  \n",
    "  \n",
    "1. nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "2. nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "white_token = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "keras_token = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 30000\n",
    "SEED = 23\n",
    "VAL_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, tokenize everything to build vocab\n",
    "Only use vocabs from train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_all_one_list = white_token.tokenize(' '.join(train['comment_text'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670966"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenize_all_one_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1.67 million tokens, do not have to use all of them as tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4261263),\n",
       " ('to', 2611234),\n",
       " ('and', 2096691),\n",
       " ('of', 2021781),\n",
       " ('a', 1880032),\n",
       " ('is', 1454734),\n",
       " ('in', 1294522),\n",
       " ('that', 1163635),\n",
       " ('for', 911179),\n",
       " ('I', 861783),\n",
       " ('you', 734810),\n",
       " ('are', 714218),\n",
       " ('be', 618319),\n",
       " ('not', 613791),\n",
       " ('have', 598834),\n",
       " ('it', 598509),\n",
       " ('on', 577471),\n",
       " ('with', 556536),\n",
       " ('as', 471924),\n",
       " ('they', 464629)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(tokenize_all_one_list).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scant', 141)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(tokenize_all_one_list).most_common(V)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 30kth token has 140 appearances, not too bad, we will use top 30k covab, and leave the rest as unknown\n",
    "This step takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocabulary.Vocabulary(tokenize_all_one_list, size=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there words that are more particular to spams?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to IDs\n",
    "While there are a few ML models that operate directly on strings, in most cases (and always for neural networks) you'll need to convert the tokens to integer IDs that can index into a feature vector. To do this, we'll need to keep track of a vocabulary, which in its simplest form is just a dictionary.  \n",
    "\n",
    "And unlike before, we are now tokenizing every row and then turn them into IDs using our vocab created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [vocab.words_to_ids(white_token.tokenize(train_row)) for train_row in train['comment_text'].tolist()]\n",
    "x_test = [vocab.words_to_ids(white_token.tokenize(test_row)) for test_row in test['comment_text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'so',\n",
       " 'cool.',\n",
       " \"It's\",\n",
       " 'like,',\n",
       " '<unk>',\n",
       " 'you',\n",
       " 'want',\n",
       " 'your',\n",
       " 'mother',\n",
       " 'to',\n",
       " 'read',\n",
       " '<unk>',\n",
       " 'Really',\n",
       " 'great',\n",
       " 'idea,',\n",
       " 'well',\n",
       " 'done!']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.ids_to_words(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149299</th>\n",
       "      <td>424798</td>\n",
       "      <td>0.6</td>\n",
       "      <td>giant hickeys.  need one down under, hahaha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>143325</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target                                 comment_text  \\\n",
       "149299  424798     0.6  giant hickeys.  need one down under, hahaha   \n",
       "\n",
       "        severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "149299              0.0      0.3              0.0     0.1     0.0    NaN   \n",
       "\n",
       "        atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "149299      NaN  ...      143325  approved      0    0    0      0         0   \n",
       "\n",
       "        sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "149299              0.6                         0                        10  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['comment_text'].str.contains(\"need one down under\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sparse input matrix\n",
    "For many language models, we need to convert inputs into a sparse matrix.   \n",
    "For example, for simple Naive Bayes BOW, we need to convert each sentence into an array containing the entire vocabulary. Each sentence would only have few words out of the entire vocab, so we will end up with a very sparse matrix, with each sentence being a row, and each row has V entries corresponding to the vocabulary.   \n",
    "  \n",
    "We have a function in utils to convert sentences into sparse matrix. In this representation, instead of printing V for each row, we only print the words that have a count > 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(train['target'] > 0.5)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = [1 if i else 0 for i in y_train]\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "['haha', 'you', 'guys', 'are', 'a', 'bunch', 'of', 'losers.']\n"
     ]
    }
   ],
   "source": [
    "for ind, y in enumerate(y_train):\n",
    "    print(y)\n",
    "    if y == 1:\n",
    "        print(ind)\n",
    "        print(vocab.ids_to_words(x_train[ind]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                          comment_text  severe_toxicity  \\\n",
       "4  59856  0.893617  haha you guys are a bunch of losers.         0.021277   \n",
       "\n",
       "   obscene  identity_attack   insult  threat  asian  atheist  ...  article_id  \\\n",
       "4      0.0         0.021277  0.87234     0.0    0.0      0.0  ...        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "4                         4                        47  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['comment_text'].str.contains(\"you guys are a bunch of\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "indices = np.arange(len(x_train))\n",
    "\n",
    "rng.shuffle(indices)  # in-place\n",
    "\n",
    "x_train =  np.array(x_train)\n",
    "y_train =  np.array(y_train)\n",
    "# the indices slicing only works with np array\n",
    "\n",
    "x_train_s = x_train[indices]\n",
    "y_train_s = y_train[indices]\n",
    "\n",
    "\n",
    "split_idx = int(VAL_SPLIT * len(x_train))\n",
    "val_x = x_train_s[:split_idx]\n",
    "val_y = y_train_s[:split_idx]\n",
    "\n",
    "train_x = x_train_s[split_idx:]\n",
    "train_y  = y_train_s[split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['Its', 'more', 'like', '<unk>', 'row,', 'i', 'would', 'hate', 'to', 'be', 'a', 'business', 'owner', 'on', 'the', 'mall', 'it', 'used', 'to', 'be', 'so', 'cool,', 'not', 'anymore', 'you', '<unk>', 'even', 'see', 'any', 'cops', 'walking', 'around,', 'pathetic.']\n"
     ]
    }
   ],
   "source": [
    "for ind, y in enumerate(train_y):\n",
    "    if y == 1:\n",
    "        print(ind)\n",
    "        print(vocab.ids_to_words(train_x[ind]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1522698</th>\n",
       "      <td>5984708</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>Its more like skid row, i would hate to be a b...</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>379755</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    target                                       comment_text  \\\n",
       "1522698  5984708  0.527027  Its more like skid row, i would hate to be a b...   \n",
       "\n",
       "         severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n",
       "1522698         0.013514  0.013514              0.0  0.540541     0.0    NaN   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1522698      NaN  ...      379755  approved      0    0    0      2         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1522698              0.0                         0                        74  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['comment_text'].str.contains(\"i would hate to be a\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['Right!', 'And', 'our', 'federal', 'government', 'is', 'just', 'overrun', 'with', 'such', '<unk>', 'people', 'who', 'never', 'ever', '<unk>', 'When', 'more', 'than', 'half', 'of', 'US', 'States', 'recognize', 'the', 'medical', 'and', '<unk>', 'recreational', 'use', 'of', 'cannabis,', 'then', 'its', 'only', 'a', 'matter', 'of', 'time', 'before', 'the', 'criminal', 'abuse', 'of', 'US', 'citizens', 'will', 'end.', 'Cannabis', 'is', 'now', 'the', 'cash', 'cow', 'of', 'the', 'judicial', 'system', 'and', 'its', 'multiple', 'private', 'contractors,', 'such', 'as', 'prison', '<unk>', '<unk>', 'outdated', 'information', 'that', 'a', 'minority', 'hopes', 'that', 'with', 'repetition', 'will', 'come', 'true,', 'is', 'a', '<unk>', 'game.', '<unk>', 'in', 'the', '<unk>', 'year', 'old', '<unk>', '<unk>', 'propaganda', 'ignores', 'the', 'reality', 'of', 'the', 'benefits', 'and', 'safety', 'of', 'cannabis', 'that', 'has', 'been', 'proven', 'scientifically', 'over', 'and', 'over', 'again.', 'Even', 'the', 'Feds', 'know', 'this', 'but', 'big', 'money', 'creates', 'filthy', 'hypocrisy.', 'Ignoring', 'proof', 'of', 'modern', '<unk>', 'and', 'global', 'medical', 'studies', 'merely', 'delays', 'the', 'inevitable,', 'and', 'costs', 'us', 'all', 'mega', 'bucks', 'and', 'individual', 'freedom.', \"Can't\", 'figure', 'out', 'if', 'this', 'minority', 'are', 'control', '<unk>', 'need', 'psych', 'care', 'or', 'are', 'just', 'plain', 'stupid.']\n"
     ]
    }
   ],
   "source": [
    "for ind, y in enumerate(val_y):\n",
    "    if y == 1:\n",
    "        print(ind)\n",
    "        print(vocab.ids_to_words(val_x[ind]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414450</th>\n",
       "      <td>750418</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Right!  And our federal government is just ove...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>157210</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target                                       comment_text  \\\n",
       "414450  750418  0.833333  Right!  And our federal government is just ove...   \n",
       "\n",
       "        severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n",
       "414450              0.0      0.0         0.166667  0.833333     0.0    NaN   \n",
       "\n",
       "        atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "414450      NaN  ...      157210  approved      0    0    0      0         0   \n",
       "\n",
       "        sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "414450              0.0                         0                         6  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['comment_text'].str.contains(\"And our federal government is just\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sb = utils.id_lists_to_sparse_bow(train_x, V)\n",
    "val_x_sb = utils.id_lists_to_sparse_bow(val_x, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x_sb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set: x = {:s} sparse, y = {:s}\".format(str(train_x_sb.shape), str(len(train_x))))\n",
    "print(\"Test set:     x = {:s} sparse, y = {:s}\".format(str(val_x_sb.shape),  str(len(val_x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "NB is used for classification, we we are going to turn the target variable into binary variable. \n",
    "This is only for testing purpose. For final model we do need a predicted probability so NB is out of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(train_x_sb, train_y)\n",
    "y_pred_val = nb.predict(val_x_sb)\n",
    "\n",
    "\n",
    "acc = accuracy_score(val_y, y_pred_val)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision, recall, fscore, support = score(val_y, y_pred_val)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for ind, val in enumerate(y_pred_val):\n",
    "    if val != val_y[ind]:\n",
    "        print(vocab.ids_to_words(val_x[ind]))\n",
    "        print(\"pred\", val, \"actual\", val_y[ind])\n",
    "        total += 1\n",
    "    if total > 5:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107928</th>\n",
       "      <td>374148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A very slippery slope here.\\n\\n-- The populari...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140595</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523812</th>\n",
       "      <td>884689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WOW!! A very slippery slope here. Equating hum...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>163562</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target                                       comment_text  \\\n",
       "107928  374148     0.0  A very slippery slope here.\\n\\n-- The populari...   \n",
       "523812  884689     0.0  WOW!! A very slippery slope here. Equating hum...   \n",
       "\n",
       "        severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "107928              0.0      0.0              0.0     0.0     0.0    NaN   \n",
       "523812              0.0      0.0              0.0     0.0     0.0    NaN   \n",
       "\n",
       "        atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "107928      NaN  ...      140595  approved      0    0    0      0         0   \n",
       "523812      NaN  ...      163562  approved      0    0    0      5         7   \n",
       "\n",
       "        sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "107928              0.0                         0                         4  \n",
       "523812              0.0                         0                         4  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['comment_text'].str.contains(\"A very slippery slope here\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonicalization\n",
    "Depending on the application, we might want to do some pre-processing to remove spurious variation in the text. For example, we might want to lowercase words to avoid storing separate features for \"I\" and \"i\", and we might want to replace numbers with a special token rather than keep track of every possible value.\n",
    "\n",
    "utils have a basic transformation in utils.canonicalize_word. It's important to write different one for different tasks since the use of language can be quite different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
